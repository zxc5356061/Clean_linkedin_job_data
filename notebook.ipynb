{"cells":[{"cell_type":"markdown","id":"0","metadata":{},"source":["## Clean Job Posting data"]},{"cell_type":"code","execution_count":1,"id":"46e74031-0632-4d09-aeb0-0eea6a4c864a","metadata":{"executionCancelledAt":null,"executionTime":813,"lastExecutedAt":1712994833054,"lastExecutedByKernel":"571aba76-ae5d-49fd-b381-ca308ecd4f00","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"import pandas as pd\nfrom thefuzz import process # Levenshtein algorithm\nimport matplotlib as plt"},"outputs":[],"source":["import pandas as pd\n","from thefuzz import process # Levenshtein algorithm\n","import matplotlib as plt"]},{"cell_type":"code","execution_count":2,"id":"1","metadata":{"chartConfig":{"bar":{"hasRoundedCorners":true,"stacked":false},"type":"bar","version":"v1","x":{"field":"R","type":"number"},"y":{"field":"index","type":"integer"}},"collapsed":false,"executionCancelledAt":null,"executionTime":69,"jupyter":{"outputs_hidden":false,"source_hidden":false},"lastExecutedAt":1712994833125,"lastExecutedByKernel":"571aba76-ae5d-49fd-b381-ca308ecd4f00","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Read csv files and drop unnecessary columns\nposting = pd.read_csv('job_postings.csv')\nposting = posting.drop(['last_processed_time','last_status','first_seen','got_summary','got_ner','is_being_worked','company','search_city','search_position'],axis=1)\n\n# print job_level requirements in different searching countries\nprint(posting.groupby(['job_level','search_country']).size())\n","outputsMetadata":{"0":{"height":227,"type":"stream"}},"visualizeDataframe":false},"outputs":[{"name":"stdout","output_type":"stream","text":["job_level   search_country\n","Associate   Australia           20\n","            Canada              49\n","            United Kingdom     115\n","            United States     1114\n","Mid senior  Australia          281\n","            Canada             581\n","            United Kingdom     880\n","            United States     9177\n","dtype: int64\n"]}],"source":["# Read csv files and drop unnecessary columns\n","posting = pd.read_csv('job_postings.csv')\n","posting = posting.drop(['last_processed_time','last_status','first_seen','got_summary','got_ner','is_being_worked','company','search_city','search_position'],axis=1)\n","\n","# print job_level requirements in different searching countries\n","print(posting.groupby(['job_level','search_country']).size())\n"]},{"cell_type":"code","execution_count":3,"id":"2","metadata":{"collapsed":false,"executionCancelledAt":null,"executionTime":126,"jupyter":{"outputs_hidden":false,"source_hidden":false},"lastExecutedAt":1712994833251,"lastExecutedByKernel":"571aba76-ae5d-49fd-b381-ca308ecd4f00","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Merge job skills with job postings of junior-level positions and clean job titles\nskill = pd.read_csv('job_skills.csv')\n\ncommon_job_titles = ['Data Analyst','Data Engineer','Data Scientist','Machine Learning Engineer','Data Entry Specialist','Data Center Technician']\n\ntop_ten_associates = []\ntop_ten_seniors = []\n\nfor level in posting['job_level'].unique():\n    df = pd.merge(posting[posting['job_level']==level],skill,how='left',on='job_link')\n    for title in common_job_titles:\n        df.loc[df['job_title'].str.contains(title), 'job_title'] = title\n    \n    # Print top 10 most popular job titles\n    print(f'Top 10 most demanding job titles in {level} level \\n{df.groupby([\"job_title\"]).size().sort_values(ascending=False).head(10)}')\n    \n    # Retrieve the top four most demanding job titles\n    if level == 'Associate':\n        top_ten_associates = df.groupby(['job_title']).size().sort_values(ascending=False).iloc[0:10].index.to_list()\n    elif level == 'Mid senior':\n        top_ten_seniors = df.groupby(['job_title']).size().sort_values(ascending=False).iloc[0:10].index.to_list()\n    else: print(\"Please check syntax\")\n","outputsMetadata":{"0":{"height":428,"type":"stream"}}},"outputs":[{"name":"stdout","output_type":"stream","text":["Top 10 most demanding job titles in Mid senior level \n","job_title\n","Data Engineer                                               1629\n","Data Analyst                                                1522\n","Data Scientist                                               723\n","Machine Learning Engineer                                    440\n","Senior MLOps Engineer                                        138\n","Data Architect                                               110\n","Manager, Data Loss Prevention (DLP) Engineer (Symantec)       57\n","Principal Associate, Data Loss Prevention (DLP) Engineer      53\n","Senior Database Administrator                                 47\n","Senior MLS Engineer, Autonomous Driving Startup               45\n","dtype: int64\n","Top 10 most demanding job titles in Associate level \n","job_title\n","Data Analyst                                321\n","Data Engineer                                96\n","Data Scientist                               80\n","Machine Learning Engineer                    21\n","Data Center Technician                       20\n","Data Entry Specialist                        15\n","Data Center Engineer                         12\n","Volunteer: Data and Salesforce Volunteer     11\n","Datacenter Technician                        10\n","Volunteer: Data Entry                         7\n","dtype: int64\n"]}],"source":["# Merge job skills with job postings of junior-level positions and clean job titles\n","skill = pd.read_csv('job_skills.csv')\n","\n","common_job_titles = ['Data Analyst','Data Engineer','Data Scientist','Machine Learning Engineer','Data Entry Specialist','Data Center Technician']\n","\n","top_ten_associates = []\n","top_ten_seniors = []\n","\n","for level in posting['job_level'].unique():\n","    df = pd.merge(posting[posting['job_level']==level],skill,how='left',on='job_link')\n","    for title in common_job_titles:\n","        df.loc[df['job_title'].str.contains(title), 'job_title'] = title\n","    \n","    # Print top 10 most popular job titles\n","    print(f'Top 10 most demanding job titles in {level} level \\n{df.groupby([\"job_title\"]).size().sort_values(ascending=False).head(10)}')\n","    \n","    # Retrieve the top four most demanding job titles\n","    if level == 'Associate':\n","        top_ten_associates = df.groupby(['job_title']).size().sort_values(ascending=False).iloc[0:10].index.to_list()\n","    elif level == 'Mid senior':\n","        top_ten_seniors = df.groupby(['job_title']).size().sort_values(ascending=False).iloc[0:10].index.to_list()\n","    else: print(\"Please check syntax\")\n"]},{"cell_type":"code","execution_count":7,"id":"3","metadata":{"collapsed":false,"executionCancelledAt":null,"executionTime":379,"jupyter":{"outputs_hidden":false,"source_hidden":false},"lastExecutedAt":1712994879938,"lastExecutedByKernel":"571aba76-ae5d-49fd-b381-ca308ecd4f00","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Extract top four associate job titles with corresponding job skills\ntop_four_associates = top_ten_associates[0:4]\n\n# temp - start\ntop_list = ('Data Scientist')\ntop_df = df.loc[df['job_title'].str.contains(top_list), :]\n## temp - end\n\nskills_df = top_df['job_skills'].apply(lambda x: x.split(', ')).apply(pd.Series)\nskills_df = skills_df.fillna('')\n\n# Count existing job skills\ncols_count = {}\nfor row in [skills_df.iloc[i,:].tolist() for i in range(0,len(skills_df))]:\n    for entry in row:\n        if entry in cols_count.keys():\n            cols_count[entry] += 1\n        else:\n            cols_count[entry] = 1\n            \n\n# Store the unique values of cuisine_type in unique_types\nunique_types = cols_count.keys()\n\n# Function to clean DataFrame based on similarity scores\ndef clean_dataframe(df, threshold=80):\n    # Count occurrences of each entry\n    cols_count = df.stack().value_counts().to_dict()\n    \n    # Calculate similarity of skills\n    skills = ['Data Analysis','Data Analytics', 'Data Visualization', 'Tableau', 'Power BI', 'SQL','.Net','A/B Testing','Business Intelligence','Database Management','Data Science']\n    \n    for skill in skills:\n        matches = process.extract(skill, cols_count.keys())\n        # Iterate through the list of matches\n        for match in matches:\n            # Check whether the similarity score is greater than or equal to threshold\n            if match[1] >= threshold:\n                # Replace the matched entry in DataFrame\n                df.replace(match[0], skill, inplace=True)\n    \n    return df\n\n\n\n# Applying cleaning function to DataFrame and some manual cleaning\ntest = clean_dataframe(skills_df)\ntest = test.replace('.*AWS.*', 'AWS', regex=True)\ntest = test.replace('.*Amazon.*', 'AWS', regex=True)\ntest = test.replace('.*Agile.*', 'Agile Method', regex=True)\ntest = test.replace('.*SQL.*', 'SQL', regex=True)\ntest = test.replace('.*API.*', 'API', regex=True)\ntest = test.replace('.*Azure.*', 'Azure', regex=True)\ntest = test.replace('.*Tableau.*', 'Data Visualization', regex=True)\ntest = test.replace('.*Power BI.*', 'Data Visualization', regex=True)\ntest = test.replace('.*Business Intelligence*', 'Data Visualization', regex=True)\ntest = test.replace('.*Data Visualisation*', 'Data Visualization', regex=True)\ntest = test.replace('.*Data Integration*', 'ETL/ELT', regex=True)\ntest = test.replace('.*Computer Science*', 'ETL/ELT', regex=True)\ntest = test.replace('.*Data validation*', 'ETL/ELT', regex=True)\ntest = test.replace('.*Data collection*', 'ETL/ELT', regex=True)\ntest = test.replace('.*Data consistency*', 'ETL/ELT', regex=True)\ntest = test.replace('.*Data integrity*', 'Data Analytics', regex=True)\ntest = test.replace('.*Data Analysis*', 'Data Analytics', regex=True)\ntest = test.replace('.*Data Exploration*', 'Data Analytics', regex=True)\ntest = test.replace('.*Extraction*', 'ETL/ELT', regex=True)\ntest = test.replace('.*Database*', 'Database Management', regex=True)\ntest = test.replace('.*Data Engineering*', 'ETL/ELT', regex=True)\ntest = test.replace('.*Data Wrangling*', 'ETL/ELT', regex=True)\ntest = test.replace('.*Data Pipelines*', 'ETL/ELT', regex=True)\ntest = test.replace('.*Data Security*', 'ETL/ELT', regex=True)\ntest = test.replace('.*Data Modeling*', 'ETL/ELT', regex=True)\ntset = test.replace('.*Data Management*', 'ETL/ELT', regex=True)\ntest = test.replace('.*python*', 'Python', regex=True)\n\n# To count cleaned skills again\ncount_clean = {}\nfor row in [test.iloc[i,:].tolist() for i in range(0,len(test))]:\n    for entry in row:\n        if entry in count_clean.keys():\n            count_clean[entry] += 1\n        else:\n            count_clean[entry] = 1\n\n            \nclean_df = pd.DataFrame.from_dict(count_clean,orient='index')\nclean_df = clean_df.reset_index()\nclean_df.rename(columns={'index':'skill',0:'counts'},inplace = True)\n# To exclude empty strings\nclean_df_sorted = clean_df[clean_df['skill'] != ''].sort_values(by='counts', ascending=False)\n\nprint(clean_df_sorted.head(20))","outputsMetadata":{"0":{"height":428,"type":"stream"}}},"outputs":[{"name":"stdout","output_type":"stream","text":["                       skill  counts\n","93        Data Visualization      75\n","31                    Python      65\n","61              Data Science      61\n","34                       SQL      56\n","109           Data Analytics      55\n","65          Machine Learning      45\n","90                   ETL/ELT      45\n","13                         R      38\n","5                 Statistics      26\n","243            Communication      20\n","75                     Spark      18\n","76                    Hadoop      18\n","0           Machine learning      17\n","41                       AWS      17\n","203              Data Mining      16\n","113               Clustering      12\n","42                      Java      12\n","1                 Regression      11\n","140  Artificial Intelligence      10\n","193               Leadership      10\n"]}],"source":["# Extract top four associate job titles with corresponding job skills\n","top_four_associates = top_ten_associates[0:4]\n","\n","# temp - start\n","top_list = ('Data Scientist')\n","top_df = df.loc[df['job_title'].str.contains(top_list), :]\n","## temp - end\n","\n","skills_df = top_df['job_skills'].apply(lambda x: x.split(', ')).apply(pd.Series)\n","skills_df = skills_df.fillna('')\n","\n","# Count existing job skills\n","cols_count = {}\n","for row in [skills_df.iloc[i,:].tolist() for i in range(0,len(skills_df))]:\n","    for entry in row:\n","        if entry in cols_count.keys():\n","            cols_count[entry] += 1\n","        else:\n","            cols_count[entry] = 1\n","            \n","\n","# Store the unique values of cuisine_type in unique_types\n","unique_types = cols_count.keys()\n","\n","# Function to clean DataFrame based on similarity scores\n","def clean_dataframe(df, threshold=80):\n","    # Count occurrences of each entry\n","    cols_count = df.stack().value_counts().to_dict()\n","    \n","    # Calculate similarity of skills\n","    skills = ['Data Analysis','Data Analytics', 'Data Visualization', 'Tableau', 'Power BI', 'SQL','.Net','A/B Testing','Business Intelligence','Database Management','Data Science']\n","    \n","    for skill in skills:\n","        matches = process.extract(skill, cols_count.keys())\n","        # Iterate through the list of matches\n","        for match in matches:\n","            # Check whether the similarity score is greater than or equal to threshold\n","            if match[1] >= threshold:\n","                # Replace the matched entry in DataFrame\n","                df.replace(match[0], skill, inplace=True)\n","    \n","    return df\n","\n","\n","# Applying cleaning function to DataFrame and some manual cleaning\n","dirty_df = clean_dataframe(skills_df)\n","dirty_df = dirty_df.replace('.*AWS.*', 'AWS', regex=True)\\\n","                    .replace('.*Amazon.*', 'AWS', regex=True)\\\n","                    .replace('.*Agile.*', 'Agile Method', regex=True)\\\n","                    .replace('.*SQL.*', 'SQL', regex=True)\\\n","                    .replace('.*API.*', 'API', regex=True)\\\n","                    .replace('.*Azure.*', 'Azure', regex=True)\\\n","                    .replace('.*Tableau.*', 'Data Visualization', regex=True)\\\n","                    .replace('.*Power BI.*', 'Data Visualization', regex=True)\\\n","                    .replace('.*Business Intelligence*', 'Data Visualization', regex=True)\\\n","                    .replace('.*Data Visualisation*', 'Data Visualization', regex=True)\\\n","                    .replace('.*Data Integration*', 'ETL/ELT', regex=True)\\\n","                    .replace('.*Computer Science*', 'ETL/ELT', regex=True)\\\n","                    .replace('.*Data validation*', 'ETL/ELT', regex=True)\\\n","                    .replace('.*Data collection*', 'ETL/ELT', regex=True)\\\n","                    .replace('.*Data consistency*', 'ETL/ELT', regex=True)\\\n","                    .replace('.*Data integrity*', 'Data Analytics', regex=True)\\\n","                    .replace('.*Data Analysis*', 'Data Analytics', regex=True)\\\n","                    .replace('.*Data Exploration*', 'Data Analytics', regex=True)\\\n","                    .replace('.*Extraction*', 'ETL/ELT', regex=True)\\\n","                    .replace('.*Database*', 'Database Management', regex=True)\\\n","                    .replace('.*Data Engineering*', 'ETL/ELT', regex=True)\\\n","                    .replace('.*Data Wrangling*', 'ETL/ELT', regex=True)\\\n","                    .replace('.*Data Pipelines*', 'ETL/ELT', regex=True)\\\n","                    .replace('.*Data Security*', 'ETL/ELT', regex=True)\\\n","                    .replace('.*Data Modeling*', 'ETL/ELT', regex=True)\\\n","                    .replace('.*Data Management*', 'ETL/ELT', regex=True)\\\n","                    .replace('.*python*', 'Python', regex=True)\n","\n","# To count cleaned skills again\n","count_clean = {}\n","for row in [dirty_df.iloc[i,:].tolist() for i in range(0,len(dirty_df))]:\n","    for entry in row:\n","        if entry in count_clean.keys():\n","            count_clean[entry] += 1\n","        else:\n","            count_clean[entry] = 1\n","\n","            \n","clean_df = pd.DataFrame.from_dict(count_clean,orient='index')\n","clean_df = clean_df.reset_index()\n","clean_df.rename(columns={'index':'skill',0:'counts'},inplace = True)\n","# To exclude empty strings\n","clean_df_sorted = clean_df[clean_df['skill'] != ''].sort_values(by='counts', ascending=False)\n","\n","print(clean_df_sorted.head(20))"]}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":5}
