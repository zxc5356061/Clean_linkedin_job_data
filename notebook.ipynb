{"cells":[{"source":"## Clean Job Posting data","metadata":{},"id":"0","cell_type":"markdown"},{"source":"import pandas as pd\n\nposting = pd.read_csv('job_postings.csv')\nposting = posting.drop(['last_processed_time','last_status','first_seen','got_summary','got_ner','is_being_worked','company','search_city','search_position'],axis=1)\nprint(posting.info())\nprint(posting.groupby(['job_level','search_country']).size())\n","metadata":{"chartConfig":{"bar":{"hasRoundedCorners":true,"stacked":false},"type":"bar","version":"v1","x":{"field":"R","type":"number"},"y":{"field":"index","type":"integer"}},"executionCancelledAt":null,"executionTime":704,"jupyter":{"outputs_hidden":true,"source_hidden":false},"lastExecutedAt":1712957474933,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"import pandas as pd\n\nposting = pd.read_csv('job_postings.csv')\nposting = posting.drop(['last_processed_time','last_status','first_seen','got_summary','got_ner','is_being_worked','company','search_city','search_position'],axis=1)\nprint(posting.info())\nprint(posting.groupby(['job_level','search_country']).size())\n","outputsMetadata":{"0":{"height":431,"type":"stream"}},"visualizeDataframe":false,"lastExecutedByKernel":"ce4fc287-1b09-4712-9568-685b14a7dd2a"},"id":"1","cell_type":"code","execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 12217 entries, 0 to 12216\nData columns (total 6 columns):\n #   Column          Non-Null Count  Dtype \n---  ------          --------------  ----- \n 0   job_link        12217 non-null  object\n 1   job_title       12217 non-null  object\n 2   job_location    12216 non-null  object\n 3   search_country  12217 non-null  object\n 4   job_level       12217 non-null  object\n 5   job_type        12217 non-null  object\ndtypes: object(6)\nmemory usage: 572.8+ KB\nNone\njob_level   search_country\nAssociate   Australia           20\n            Canada              49\n            United Kingdom     115\n            United States     1114\nMid senior  Australia          281\n            Canada             581\n            United Kingdom     880\n            United States     9177\ndtype: int64\n"}]},{"source":"skill = pd.read_csv('job_skills.csv')\ndf = pd.merge(posting[posting['job_level']=='Associate'],skill,how='left',on='job_link')\n\ndf.loc[df['job_title'].str.contains('Data Analyst'), 'job_title'] = 'Data Analyst'\ndf.loc[df['job_title'].str.contains('Data Engineer'), 'job_title'] = 'Data Engineer'\ndf.loc[df['job_title'].str.contains('Data Scientist'), 'job_title'] = 'Data Scientist'\ndf.loc[df['job_title'].str.contains('Machine Learning Engineer'), 'job_title'] = 'Machine Learning Engineer'\ndf.loc[df['job_title'].str.contains('Data Entry Specialist'), 'job_title'] = 'Data Entry Specialist'\n\n# print(df.groupby(['job_title']).size().sort_values(ascending=False).head(10))","metadata":{"executionCancelledAt":null,"executionTime":82,"jupyter":{"outputs_hidden":false,"source_hidden":false},"lastExecutedAt":1712957475015,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"skill = pd.read_csv('job_skills.csv')\ndf = pd.merge(posting[posting['job_level']=='Associate'],skill,how='left',on='job_link')\n\ndf.loc[df['job_title'].str.contains('Data Analyst'), 'job_title'] = 'Data Analyst'\ndf.loc[df['job_title'].str.contains('Data Engineer'), 'job_title'] = 'Data Engineer'\ndf.loc[df['job_title'].str.contains('Data Scientist'), 'job_title'] = 'Data Scientist'\ndf.loc[df['job_title'].str.contains('Machine Learning Engineer'), 'job_title'] = 'Machine Learning Engineer'\ndf.loc[df['job_title'].str.contains('Data Entry Specialist'), 'job_title'] = 'Data Entry Specialist'\n\n# print(df.groupby(['job_title']).size().sort_values(ascending=False).head(10))","outputsMetadata":{"0":{"height":257,"type":"stream"}},"collapsed":false,"lastExecutedByKernel":"ce4fc287-1b09-4712-9568-685b14a7dd2a"},"id":"2","cell_type":"code","execution_count":2,"outputs":[]},{"source":"\n# top_list = ('Data Analyst|Data Engineer|Data Scientist|Machine Learning Engineer')\n\ntop_list = ('Data Scientist')\ntop_df = df.loc[df['job_title'].str.contains(top_list), :]\n# print(top_df.info())\n\nskills_df = top_df['job_skills'].apply(lambda x: x.split(', ')).apply(pd.Series)\n# print(skills_df.columns)\nskills_df = skills_df.fillna('')\n\n# print(skills_df)\n\ncols_count = {}\nfor row in [skills_df.iloc[i,:].tolist() for i in range(0,len(skills_df))]:\n    for entry in row:\n        if entry in cols_count.keys():\n            cols_count[entry] += 1\n        else:\n            cols_count[entry] = 1\n\nprint(cols_count) ","metadata":{"executionCancelledAt":null,"executionTime":103,"jupyter":{"outputs_hidden":false,"source_hidden":false},"lastExecutedAt":1712957475118,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"\n# top_list = ('Data Analyst|Data Engineer|Data Scientist|Machine Learning Engineer')\n\ntop_list = ('Data Scientist')\ntop_df = df.loc[df['job_title'].str.contains(top_list), :]\n# print(top_df.info())\n\nskills_df = top_df['job_skills'].apply(lambda x: x.split(', ')).apply(pd.Series)\n# print(skills_df.columns)\nskills_df = skills_df.fillna('')\n\n# print(skills_df)\n\ncols_count = {}\nfor row in [skills_df.iloc[i,:].tolist() for i in range(0,len(skills_df))]:\n    for entry in row:\n        if entry in cols_count.keys():\n            cols_count[entry] += 1\n        else:\n            cols_count[entry] = 1\n\nprint(cols_count) ","outputsMetadata":{"0":{"height":366,"type":"stream"}},"collapsed":false,"lastExecutedByKernel":"ce4fc287-1b09-4712-9568-685b14a7dd2a"},"id":"3","cell_type":"code","execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":"{'Machine learning': 17, 'Regression': 11, 'Natural Language Processing (NLP)': 1, 'Neural networks': 3, 'Quantitative research methods': 1, 'Statistics': 26, 'Bayesian analysis': 1, 'Pandas': 7, 'Scikitlearn': 7, 'Stats models': 1, 'TensorFlow': 8, 'MXNet': 1, 'SageMaker': 2, 'R': 38, 'API development': 1, 'Java frameworks': 1, 'Web services': 1, 'UI development': 1, 'Git': 6, 'Atlassian Jira': 1, 'Atlassian Confluence': 1, 'Slack': 1, 'Agile methodology': 1, 'Computer science': 6, 'Mathematics': 9, 'Physics': 2, 'Economics': 5, 'Engineering': 8, 'Operations research': 3, 'Quantitative social science': 1, '': 6940, 'Python': 65, 'RDBMS': 1, 'Kafka': 3, 'SQL': 45, 'PySpark': 4, 'Hive': 9, 'Logistic regression': 5, 'Na√Øve Bayes': 1, 'SVM': 2, 'Decision trees': 1, 'AWS': 10, 'Java': 12, 'Tensorflow': 3, 'PyTorch': 8, 'Natural Language Processing': 9, 'ML systems': 1, 'Streaming data flows': 1, 'Electrical engineering': 1, 'Econometrics': 5, 'Signal processing': 1, 'ETL data pipeline': 1, 'Data engineering': 2, 'Predictive analytics': 2, 'Prototyping': 2, 'Model validation': 1, 'A/B testing': 1, 'Model efficiency': 1, 'Model performance': 1, 'Fintech': 1, 'Legal industry': 1, 'Data Science': 45, 'Sklearn': 4, 'Data Structures': 6, 'Algorithms': 6, 'Machine Learning': 45, 'Recommender Systems': 3, 'Classifiers': 1, 'Chatbots': 1, 'Jupyter Notebooks': 3, 'MLflow': 4, 'Databricks': 9, 'AWS Cloud Solutions': 2, 'S3': 4, 'Glue': 1, 'Lambda': 1, 'Spark': 18, 'Hadoop': 18, 'Pig': 1, 'HiveQL': 1, 'Pig Latin': 1, 'Oozie': 1, 'Flume': 1, 'Sqoop': 1, 'HBase': 1, 'Cassandra': 3, 'MongoDB': 1, 'Redis': 1, 'Elasticsearch': 1, 'Kibana': 1, 'Logstash': 1, 'Computer Science': 12, 'Numpy': 3, 'Data mining': 4, 'Business Intelligence': 4, 'Analytical thinking': 1, 'Problemsolving': 2, 'Research': 4, 'Production environments': 1, 'Scalability': 1, 'Business acumen': 3, 'Data science': 12, 'Statistical methods': 2, 'Regression analysis': 1, 'Stata': 1, 'SAS': 9, 'SPSS': 3, 'Geographic Information Systems (GIS)': 1, 'Alteryx': 1, 'AI/Machine learning': 1, 'Retail location analytics': 1, 'Data analysis': 11, 'Data cleansing': 1, 'Data structuring': 1, 'Predictive modeling': 8, 'Clustering': 12, 'Classification': 10, 'C': 2, 'C++': 6, 'Tableau': 21, 'Analytics': 4, '* Data Science': 1, '* Translational Bioinformatics': 1, '* Machine Learning': 1, '* Python': 1, '* Statistics': 1, '* Predictive Statistics': 1, '* Probability Theory': 1, '* Biology': 1, '* Rare Diseases': 1, '* HardtoDiagnose Diseases': 1, '* Diagnostic Disease Signatures': 1, '* Actionable Targets': 1, '* Drug Development': 1, '* Model Building': 1, '* Model Scoring': 1, '* Human Health': 1, '* Disease Outcomes': 1, '* PhD': 1, '* PostDoctoral Experience': 1, '* MS Degree': 1, '* 8+ Years of Experience': 1, '* Ability to Work in the United States': 1, '* Friendly Personality': 1, '* Easygoing Personality': 1, 'Artificial Intelligence': 10, 'Credit Underwriting': 2, 'Risk Management': 4, 'Business English': 1, 'Spanish': 1, 'Data Analysis': 19, 'Software Development': 4, 'Financial Services': 2, 'Business Acumen': 5, 'Tech Startups': 1, 'Data:': 1, 'Data Analytics': 10, 'Data Extraction': 4, 'Data Modeling': 7, 'Data Engineering': 6, 'Languages:': 1, 'Frameworks:': 1, 'PowerBI': 3, 'Cloud:': 1, 'Azure': 4, 'GCP': 2, 'Concepts:': 1, 'Deep Neural Networks': 1, 'Entity Extraction': 2, 'Requirements:': 1, \"Master's in Engineering Computer Science Sciences Mathematics or related field\": 1, '2 years of experience in Machine Learning and Artificial Intelligence': 1, '2 years of experience with AWS Azure and GCP': 1, '2 years of experience in customizing pretrained ML models': 1, 'Scientific principles': 1, 'Materials challenges': 1, 'Materials discovery': 1, 'Mathematical foundations': 1, 'Computational modeling': 1, 'Densityfunctional theory': 1, 'Molecular dynamics': 1, 'Physical Science': 1, 'Data informatician': 1, 'Materials informatics capabilities': 1, 'Material property calculations': 1, 'JavaScript': 1, 'Fortran': 1, 'Cloud environment': 2, 'Containerisation technology': 1, 'Docker': 5, 'Sustainability': 1, 'Material sustainability': 1, 'Peerreviewed publications': 1, 'Stock Options': 1, 'Flexible holidays': 1, 'Flexible work arrangements': 1, 'Continuous learning and growth': 1, 'Data parsing': 1, 'Data visualization': 8, 'Quantitative strategies': 1, 'Data sources management': 1, 'Pattern recognition': 1, 'Derived variables': 1, 'Statistical analysis': 8, 'Linux': 1, 'Bash': 2, 'Collaborative environment': 1, 'Decisionmaking': 1, 'Leadership': 10, 'Healthcare': 1, 'Insurance': 1, 'MATLAB': 5, 'PowerPoint': 3, 'Programming for Data Science': 2, 'Predictive Analytics': 3, 'Prescriptive Analytics': 3, 'Supervised Learning': 5, 'Unsupervised Learning': 5, 'Data Mining': 16, 'Monte Carlo Simulations': 2, 'Simulation of Wildfires': 1, 'Catastrophe Modeling': 1, 'Technical Writing': 2, 'Model Development': 1, 'Model Testing': 1, 'Data Collection': 8, 'CrossFunctional Collaboration': 2, 'Problem Solving': 8, 'Independent Work': 1, 'Minimal Supervision': 1, 'Deep Learning': 9, 'Computer Vision': 5, 'Open CV': 1, 'Object Detection': 1, 'Image Segmentation': 1, 'Cloud Computing': 6, 'CI/CD Pipelines': 1, 'MLOps': 4, 'Data Visualization': 24, 'Grafana': 1, 'MS Office': 1, \"Bachelor's Degree\": 3, \"Master's Degree\": 2, 'Thesis': 1, 'Experience': 1, 'Industry Experience': 1, 'Operations Research': 7, 'Model Deployment': 1, 'Data Ingestion': 2, 'Statistical Rigor': 2, 'Software Design': 1, 'Confluence': 2, 'GitHub': 3, 'Knowledge Management': 1, 'Troubleshooting': 1, 'Experimentation': 5, 'Design Patterns': 2, 'Math': 2, 'Programming': 7, 'Communication': 20, 'Critical Thinking': 2, 'Natural Language Understanding': 1, 'Sentiment Analysis': 1, 'Predictive Modeling': 10, 'Big Data': 3, 'Scala': 8, 'H2O.ai': 1, 'Sagemaker': 3, 'Distributed Computing': 1, 'Matplotlib': 3, 'Seaborn': 4, 'XGBoost': 1, 'Random Forest': 2, 'Logistic Regression': 1, 'Shapley': 1, 'Lime': 1, 'Neural Network': 1, 'LLM': 1, 'ETL': 2, 'Snaplogic': 1, 'Mulesoft': 1, 'Informatica': 1, 'Stitch': 1, 'NoSQL': 3, 'Sales/Marketing Domain': 1, 'Visualization': 3, 'Courageous Team Collaboration': 1, 'Epic Scale Delivery': 1, 'Curious Learning': 1, 'Act Like an Owner & Doer': 1, 'Giving Back to Others': 1, 'Equality and Equity': 1, 'Ethical Conduct': 1, 'Virtual Assistants': 2, 'Blockchain': 5, 'MicroLeadership': 1, 'Service Learning': 2, 'Project Management': 6, 'Analytical Mindset': 1, 'Math Skills': 1, 'Algebra': 1, 'Communication Skills': 5, 'Presentation Skills': 2, 'BSc/BA in Computer Science': 1, 'Graduate Degree in Data Science': 1, 'Artificial intelligence': 4, 'Virtual assistants': 2, 'Social impact currency': 1, 'Open platform': 1, 'Microleadership': 3, 'Service learning': 2, 'Massively multidisciplinary collaboration': 2, 'Project managers': 2, 'Human resource business partners': 2, 'Educational data scientist': 1, 'Data interpretation': 2, 'Statistical tools and methods': 1, 'Data insights': 1, 'Iterative improvements': 1, 'Data privacy': 1, 'Data security': 1, 'Data Scientist': 4, 'Digitalization projects': 1, 'Research investigations': 1, 'Datadriven studies': 1, 'Statistical packages': 1, 'Data modeling platforms': 1, 'Machine learning techniques': 1, 'Graphical models': 1, 'Mixture models': 1, \"Master's degree in biostatistics epidemiology public health psychology statistics\": 1, 'Ph.D. in statistics mathematics or data science': 1, 'Experience presenting regulatory positions and determinations to insurance company representatives': 1, 'Experience applying statistical research and techniques to projects': 1, 'Insurance membership with Fellow of Casualty Actuarial Society (FCAS) or Associate Casualty Actuarial Society (ACAS)': 1, 'Certified Specialist in Predictive Analytics (CSPA) credential': 1, 'Considerable knowledge of methods of research design statistical analysis and database management': 1, 'Considerable knowledge of management systems research and development related to social and economic trends': 1, 'Considerable knowledge of relevant State and Federal statutes regulations and guidelines': 1, 'Knowledge of data processing computer programming for statistical analysis': 1, 'Knowledge of data retrieval and analysis methods': 1, 'Considerable written and oral communication skills': 1, 'Considerable interpersonal skills': 1, 'Ability to conduct longitudinal investigations/research including interviewing and performing trend analyses and outcome effectiveness studies': 1, 'Ability to analyze and evaluate data using multiple regression log linear analyses factor analyses and multivariate analyses': 1, 'Ability to use statistical packages and/or various data modeling platforms': 1, 'Ability to design and conduct studies and determine effective solutions': 1, 'Ability to write technical reports': 1, 'Some supervisory ability': 1, 'Forecasting': 4, 'Programming Languages (Java NodeJS Python R)': 1, 'Cloud and Big Data Technologies (Microsoft Azure Azure Data Lake Databricks Google Cloud Platform Apache Spark)': 1, 'Analytics Skills (Descriptive Statistical Modeling & Algorithms Machine Learning Algorithms Modeling Dataset Building Optimization Data Visualization Pattern/Cluster/Segmentation Analysis Predictive Analytics)': 1, 'Analytics Tools and Technologies (QlikView Cognos Visual Basic Apache Oracle SQL GraphQL NoSQL)': 1, 'DevOps': 1, 'Advanced Computing': 1, 'Core Analytic Methods (Predictive Modeling Customer Segmentation/Clustering Network Analysis Supply Chain Optimization)': 1, 'Business Sense': 1, 'ML Techniques': 1, 'Statistical Concepts': 1, 'Machine Learning Frameworks': 1, 'ML Platforms': 1, 'Data Products': 4, 'Reinforcement Learning': 5, 'Optimisation': 1, 'Distributed Systems': 2, 'CloudBased Systems': 1, 'Amazon EC2': 1, 'Mentoring': 4, 'AWS SageMaker': 1, 'Human Resource Business Partners': 1, 'Wildfire Prevention Financing': 1, 'Prevention Derivatives': 1, 'Geographic Information Systems': 1, 'Visual Analytics': 1, 'Trend Analysis': 1, 'Statistical Modeling': 4, 'Scenario Building': 1, 'Wind Energy': 1, 'HighPerformance Computing': 2, 'AI': 4, 'Digital Processes': 1, 'Data Management': 3, 'Numerical Modelling': 1, 'Weather Research and Forecasting': 1, 'ECMWFERA5': 1, 'Reanalysis Models': 1, 'Scripting': 2, 'NLP': 4, 'Recommendation Systems': 1, 'Esports': 1, 'Game Development': 1, 'Game Publishing': 1, 'LiveOps': 1, 'LargeScale Data Analysis': 1, 'Anomaly Detection': 3, 'Simulation': 4, 'Optimization': 8, 'Information Retrieval': 3, 'Power BI': 5, 'Collaboration': 5, 'Statistical Analysis': 10, 'Statistical Computing': 1, 'Sports Data': 1, 'Football Data': 1, 'Injury Prevention': 1, 'Performance Analysis': 1, 'Sports Science': 1, 'Medicine': 1, 'Data Processing': 2, 'Tactical Research': 1, 'Player Performance': 1, 'DataDriven Decision Making': 4, 'Lead Data Scientist': 1, 'Data collection': 1, 'Data quality': 2, 'Data integrity': 1, 'Data management': 2, 'Communication skills': 6, 'Critical thinking': 1, 'Problem solving': 3, 'R Programming': 1, 'Data Interpretation': 3, 'Semiconductor Analysis': 1, 'Biotechnology': 1, 'Experimental Design': 1, 'Report Writing': 1, 'ProblemSolving': 1, 'Attention to Detail': 2, 'MS in Biomedical Engineering': 1, 'MS in Data Science': 1, '2+ Years R Experience': 1, 'Knime': 1, 'Consultancy': 3, 'DataDriven DecisionMaking': 2, 'Team Management': 1, 'Analytical Techniques': 1, 'Emerging Technologies': 1, 'Translational Bioinformatics': 1, 'Rare and HardtoDiagnose Diseases': 1, 'Programming Skills': 1, 'Biology': 1, 'Model Building': 2, 'Disease Prediction': 1, 'Relational databases': 3, 'Opensource programming languages': 1, 'Cloudbased solutions': 1, 'Statistical modeling': 3, 'Causal inference': 3, 'Hypothesis testing': 2, 'Linear regression': 2, 'Generalized additive models': 1, 'Bayesian statistics': 1, 'Timeseries': 1, 'Nonparametric modeling': 1, 'Feature engineering': 1, 'Data manipulation': 1, 'Model evaluation': 1, 'Model deployment': 1, 'Deep learning': 5, 'Research and innovation': 1, 'Collaboration skills': 1, 'Problemsolving skills': 2, 'Continuous learning': 2, \"Master's or Ph.D.\": 1, 'Experience as a Data Scientist': 1, 'Strong academic background': 1, 'Huggingface': 1, 'VectorDB': 1, 'Pytorch': 2, 'ElasticSearch': 1, 'Software Engineering': 2, 'Product Management': 1, 'Customer Relationship Management': 1, 'Data Pipelines': 4, 'Serverless Computing': 1, 'Cloud Computing Services': 1, 'Data Science Solutions': 1, 'Computer Programming': 2, 'Technology': 2, 'Science': 1, 'Large Language Models': 2, 'Statistical learning': 1, 'Agile': 3, 'Code versioning': 1, 'UNIX': 2, 'Highperformance computing clusters': 1, 'Mathematical modelling': 1, 'Statistical modelling': 1, 'Business analysis': 1, 'Hierarchical mixed bayesian models': 1, 'Transformerbased NLP models': 1, 'Reinforcement learning': 2, 'Deep learning models': 1, 'CNN/RNN/LSTM': 1, 'GNNs': 2, 'Constrained optimization': 1, 'Time series': 2, 'Forecasting models': 1, 'Life sciences industry experience': 1, 'Machine Learning (ML)': 1, 'Artificial Intelligence (AI)': 2, 'Statistical Modelling': 1, 'Data Transformation': 5, 'Feature Engineering': 2, 'Pattern Recognition': 1, 'Predictive Modelling': 1, 'Excel': 5, 'Cloud Platforms': 1, 'Algorithm Implementation': 1, 'PatientCentric Solutions': 2, 'Thought Partnership': 1, 'Strategic Goal Understanding': 1, 'Statistical Methodologies': 2, 'HypothesisDriven Analyses': 1, 'Machine Learning Algorithms': 1, 'Optimization Algorithms': 1, 'Data Science Pipelines': 2, 'Big Data Analytics': 1, 'Data Warehousing': 4, 'Dash': 4, 'Angular': 4, 'Relational Databases': 2, 'Snowflake': 1, 'Applied Econometrics': 2, 'Industrial Engineering': 3, 'Advanced Analytics': 3, 'Team Collaboration': 1, 'Research & Development': 1, 'Methods': 1, 'PH.D': 1, 'Statistical techniques': 1, 'Databases': 2, 'Scrum': 2, 'C#': 2, 'Microsoft SQL Server': 1, 'Kubernetes': 2, 'HDFS': 1, 'Redshift': 2, 'Airflow': 1, 'Quantitative Analysis': 2, 'Decentralized Finance': 1, 'MEV (Miner Extractable Value)': 1, 'Fullstack': 1, 'Ethereum': 1, 'Synapse Analytics': 1, 'Apache Spark': 1, 'Microsoft Azure': 2, 'SQL Server': 3, 'Stakeholder Engagement': 2, 'Linear Regression': 1, 'Generalized Additive Model': 1, 'Decision Tree Learning': 1, 'Artificial Neural Networks': 1, 'Generative AI': 3, 'Statistical inference': 1, 'Operational research': 1, 'Unstructured Data': 3, 'Semistructured Data': 1, 'Data Governance': 4, 'Data Storage': 1, 'Data Security': 3, 'Data Quality': 1, 'Data Integrity': 1, 'Data Reporting': 2, 'U.S. Citizenship': 1, 'TS/SCI Security Clearance': 2, 'Polygraph Examination': 1, 'Drug Testing': 1, \"Veterans' Preference\": 1, 'Equal Employment Opportunity': 1, 'Reasonable Accommodation': 1, 'Emergency Essential': 1, 'Geographic Mobility': 1, 'Information Assurance': 1, 'DCIPS Targeted Local Market Supplement (TLMS) STEM pay': 1, 'Trial Period': 1, 'Marketing': 1, 'Machine Learning Engineering': 1, 'Game Science': 1, 'Recommender system': 1, 'Data Exploration': 3, 'Data Cleaning': 2, 'Statistical Programming': 2, 'EMR': 2, 'MapReduce': 2, 'MySQL': 2, 'Gurobi': 3, 'Plotly': 3, 'ggplot2': 2, 'Predictive Variables': 1, 'Algorithm Creation': 1, 'Statistical Learning Models': 1, 'Predictive Models': 1, 'Database Use': 1, 'Data Integration': 3, 'Web Services': 1, 'Qualitative Analysis': 1, 'Bioinformatics': 2, 'Data processing': 1, 'R/Bioconductor': 1, 'Unix': 1, 'Highperformance computing': 1, 'Molecular biology': 1, 'Cellular biology': 1, 'Biological databases': 1, 'Web tools': 1, 'Presentation skills': 2, 'Team working ability': 1, 'Problemsolving mindset': 1, 'Organizational skills': 1, 'Enthusiastic': 1, 'Collaborative spirit': 1, 'Interpersonal skills': 2, 'English': 1, 'Pacbio': 1, 'Oxford Nanopore': 1, 'Omics data': 1, 'Data integration': 1, 'Cloud computing': 3, 'Webbased deployment': 1, 'PhD': 3, 'MS': 1, 'Industry experience': 2, 'Planning': 1, 'Microsoft Office Suite': 2, 'Data Representation': 1, 'Data Reduction': 2, 'Data Views': 1, 'Data Reuse': 1, 'Applied Statistics': 1, 'Systems Analysis': 2, 'Systems Engineering': 1, 'TS Clearance': 1, 'SCI Clearance': 1, 'Computer Coding': 1, 'Database Management': 1, 'Network Services Planning': 1, 'DOD Experience': 1, 'US Citizenship': 1, 'Endtoend solutions': 1, 'Business insights': 2, 'Datadriven organization': 1, 'Thought partner': 1, 'Strategic goals': 1, 'Subject matter expertise': 1, 'Impacful insights': 1, 'Business decisions': 1, 'Patient benefits': 1, 'Compass': 1, 'Decision support': 1, 'Enterprise': 1, 'Rigorous analytical expertise': 1, 'Dynamic': 1, 'Exciting': 1, 'Subjectmatter experts': 1, 'Diverse': 1, 'Market research': 1, 'Digital analytics': 1, 'Finance': 1, 'Consulting': 1, 'Iteratively': 1, 'Rapidly': 1, 'Open feedback': 1, 'Debate': 1, 'Team sport': 1, 'Independent decisionmaking': 1, 'Smart risks': 1, 'Brand': 1, 'US Commercial': 1, 'Business': 1, 'Digital teams': 1, 'Models': 1, 'Insights': 2, 'Data products': 2, 'Strategic priorities': 1, 'Product/brand strategy': 1, 'Therapeutic area': 1, 'Crossfunctional teams': 1, 'Growth opportunities': 1, 'Data requirements': 1, 'Critical metrics': 1, 'Experiments': 2, 'Adoption': 1, 'Business performance': 1, 'Patient experience': 1, 'Hypothesisdriven': 1, 'Exploratory analyses': 1, 'ML algorithms': 2, 'Optimization engines': 1, 'Data solutions': 1, 'New technologies': 1, 'Technical capabilities': 1, 'Senior management': 1, 'Businessfocused takeaways': 1, 'Bachelor‚Äôs degree': 1, '5+ years of experience': 1, 'Masters Degree': 1, '3+ years of experience': 1, '02 years of experience': 1, 'Snowflake/Databricks': 1, 'Anomaly detection': 2, 'Statistical methodologies': 1, 'Bayesian': 1, 'Nonparametric techniques': 1, 'ANOVA': 1, 'Fixed and random effects': 1, 'Big data': 1, 'Clickstream': 1, 'Unstructured data': 1, 'Senior business executives': 1, 'Senior Data Scientist': 1, 'Data Science Programming': 1, 'Data Manipulation': 2, 'Data Cataloguing': 1, 'Protein Structure Analysis': 1, 'Protein Data Bank (PDB)': 1, 'Keras': 3, 'Graph Neural Networks': 1, 'Geometric Deep Learning': 1, 'Generative Models': 1, 'Multiomics Data': 1, 'TCGA': 1, 'DepMap': 1, 'GTEx': 1, 'Human Cell Atlas': 1, 'Cancer Biology': 1, 'Immunology': 1, 'Workflow Language': 1, 'Nextflow': 1, 'Web Development': 1, 'Javascript': 2, 'Natural language processing': 1, 'Data warehousing': 1, 'Teamwork': 4, 'Time management': 2, 'Project management': 1, 'NumPy': 1, 'Business intelligence software': 1, 'Data mining techniques': 1, 'Statistical analysis methodology': 1, 'Machine learning models': 1, 'Regression modeling': 1, 'Probability distribution fitting': 1, 'Stochastic simulation': 1, 'Multivariate sensitivity analysis': 1, 'Microsoft Office': 1, 'APIs': 1, 'ML production environments': 1, 'Feature selection': 1, 'Dimensionality reductions': 1, 'Timeseries data analysis': 1, 'Prediction modeling': 1, 'ARIMA': 1, 'SARIMA': 1, 'Exponential smoothing': 1, 'Neural Networks': 3, 'ReLU': 1, 'Sigmoid': 1, 'Activation functions': 1, 'Data reporting': 1, 'Data literacy': 1, 'Data science capabilities': 1, 'Crossfunctional growth': 1, 'Prescriptive analytics': 1, 'Data cleaning': 1, 'Data preparation': 1, 'Data compression': 1, 'Binning': 1, 'Normalization': 1, 'Scaling': 1, '1hot encoding': 1, 'Matrix operations': 1, 'Multidimensional array operations': 1, 'Table operations': 1, 'Decision tree analysis': 2, 'Boosting': 2, 'Principal Component Analysis': 1, 'Business Analytics': 1, 'Descriptive Analytics': 1, 'Diagnostic Analytics': 1, 'Data Literacy': 1, 'Innovation': 1, 'Automation': 1, 'Data Cleansing': 2, 'Data Privacy': 1, 'Data Ethics': 1, 'DataDriven Insights': 1, 'DataDriven Strategies': 1, 'DataDriven Innovation': 1, 'DataDriven Transformation': 1, 'DataDriven Culture': 1, 'Coding': 1, 'Jupyter Notebook': 1, 'Advanced Statistical Techniques': 1, 'Speech Recognition': 1, 'Fraud Detection': 1, 'Risk Assessment': 2, 'Compliance': 1, 'Governance': 1, 'Audit': 1, 'Internal Audit': 1, 'External Audit': 1, 'Financial Audit': 1, 'Operational Audit': 1, 'IT Audit': 1, 'Risk Audit': 1, 'Compliance Audit': 1, 'Internal Controls': 1, 'Corporate Governance': 1, 'SarbanesOxley Act': 1, 'DoddFrank Wall Street Reform and Consumer Protection Act': 1, 'Basel III': 1, 'International Financial Reporting Standards': 1, 'Generally Accepted Accounting Principles': 1, 'Cybersecurity': 1, 'Information Security': 1, 'Network Security': 1, 'Application Security': 1, 'Cloud Security': 1, 'Physical Security': 1, 'Business Continuity': 1, 'Disaster Recovery': 1, 'Incident Response': 1, 'Penetration Testing': 1, 'Vulnerability Assessment': 1, 'Security Awareness Training': 1, 'Security Compliance': 1, 'Security Policies': 1, 'Security Procedures': 1, 'Security Standards': 1, 'Security Best Practices': 1, 'EndtoEnd Solutions': 1, 'Business Insights': 1, 'Data Requirements': 1, 'Critical Metrics': 1, 'Optimization Engines': 1, 'Coaching': 1, 'IoT': 2, 'GeneralPurpose Programming': 1, 'Structured Data': 1, 'Predictive Data Modeling': 1, 'Quantitative Analyses': 1, 'Visualization Packages': 1, 'SQL/NoSQL': 1, 'Distributed Data/Computing Tools': 1, 'TS/SCI Clearance': 1, 'Remote Work Option': 1, 'Collaborative Environment': 1, 'Competitive Salary': 1, 'Benefits Package': 1, 'Tuition/Education Assistance': 1, 'Personal Computer Device Allowance': 1, 'Pet Insurance': 1, 'Inclusion and Diversity': 1, 'Equal Opportunity Employer': 1, 'Machine Learning Engineer': 1, 'Automated Credit Model': 1, 'Machine Learning Models': 1, 'Loss Rates': 1, 'Profitability Analysis': 1, 'Modeling': 4, 'Spanish Language (Fluent/Comfortable)': 1, 'Startup Experience': 1, 'Team Leadership': 1, 'Equity': 1, 'Stock Option Grants': 1, 'Competitive Compensation': 1, 'Bonuses': 1, 'Paid Time Off': 1, 'Holidays': 2, 'Linear Algebra': 1, 'Matrix Functions': 1, 'Analytic Frameworks': 1, 'Open Source Libraries': 1, 'Model Reproducibility': 1, 'Experimentation at Scale': 1, 'Bachelors in STEM': 1, 'Masters in Comp Science': 1, 'PhD STEM': 1, 'Verbal Communication Skills': 1, 'Applied Math': 1, 'Bayesian Statistics': 1, 'Frequentist Statistics': 1, 'EEO Guidelines': 1, 'Mathematical modeling': 1, 'Generalized Additive Models (GAM)': 1, 'Hierarchical Linear Mixed Effects (HLM) Regression': 1, 'Generalized Linear Models (GLM)': 1, 'Classification and Regression ensembling': 1, 'Latent Analysis and Structural Equation Modeling (SEM)': 1, 'Unsupervised clustering segmentation models': 1, 'Microsoft PowerBI': 1, 'Data presentation': 1, 'Analytical skills': 1, 'Critical thinking skills': 1, 'Teamwork skills': 1, 'Leadership skills': 1, 'Initiative': 1, 'Selfmotivation': 1, 'Attention to detail': 1, 'Time management skills': 1, 'Organization skills': 1, 'Flexibility': 1, 'Agility': 1, 'Statistical Learning': 1, 'Clinical Trials': 1, 'Biomedical Data': 1, 'Digital Therapeutics': 1, 'Diagnostics': 1, 'Endpoints': 1, 'Code Versioning': 1, 'Business Analysis': 2, 'Hierarchical Mixed Bayesian Models': 1, 'Transformerbased NLP Models': 1, 'Constrained Optimization': 1, 'Time Series': 1, 'Forecasting Models': 1, 'Library Science and Information Studies': 1, 'Library Systems': 1, 'German': 1, 'French': 1, 'Distributed computing': 1, 'Problem formulation': 1, 'Exploratory data analysis': 1, 'Presentation': 3, 'Teambuilding': 1, 'Data structures': 1, 'Design patterns': 1, 'Error correction': 1, 'Quantitative analytics': 1, 'Data Modelling': 1, 'Cloud Deployment': 1, 'Agile Framework': 1, 'Risk Mitigation': 1, 'Revenue Growth': 1, 'Operational Efficiency': 1, 'Analytical Skills': 1, 'MSc in Data Science': 1, '4+ Years Experience in Data Science': 1, 'Building algorithms': 1, 'Model training': 1, 'Data patterns': 1, 'Predictive models': 1, 'Graphical model analysis': 1, 'Machine learning foundation': 1, 'Softwarefocused marketing': 1, 'Verbal communication': 1, 'Written communication': 1, 'Multitasking': 1, 'Creative problem solving': 1, 'Goal orientation': 1, 'Organization': 1, 'Teamplayer': 1, 'Leading': 1, \"Bachelor's degree\": 1, \"Master's degree\": 1, 'Machine learning tools and techniques': 1, 'Relational database design': 1, 'Programming languages': 1, 'Genetic algorithms': 1, 'PCA': 1, 'Industry trends': 1, 'Fastpaced environment': 1, 'Statistical Reporting': 1, 'Agile Software Development': 1, 'AWS Databases': 1, 'SciKitLearn': 1, 'Stable Diffusion': 1, 'GPT': 1, 'HuggingFace': 1, 'CNN': 1, 'Transformer': 1, 'Time Series Analysis': 2, 'Sequence Modeling': 1, 'MixedReality Platforms': 1, 'AWSSageMaker': 1, 'Sensor Deployments': 1, 'Dashboarding Frameworks': 1, 'Bokeh': 1, 'Data Standardization': 1, 'Data Structuring': 2, 'Data Presentation': 1, 'Portfolio Management': 1, 'Energy Trading': 1, 'Renewables': 1, 'Cleantech': 1, 'Agile Methodologies': 1, 'CPLEX': 1, 'Shiny': 1, 'Interpretable Models': 1, 'Dynamic Models': 1, 'Scalable Models': 1, 'Master Table Design': 1, 'Multiuse Case Engagements': 1, 'Hypothesis Testing': 1, 'Analytics Roadmap': 1, 'Cutting Edge Approaches': 1, 'Complexity Factors': 1, 'Data Pipeline': 1, 'Ambiguity Tolerance': 1, 'Opensource Optimization Libraries': 1, 'Dashboarding Tools': 1, 'MLOps Infrastructure': 1, 'Containerization': 2, 'Production Pipelines': 1, 'Microservices': 1, 'Qlik': 1, 'VBA': 2, 'Storytelling': 2, 'Gathering requirements': 1, 'Waterfall': 1, 'Document Understanding': 1, 'Transfer Learning': 1, 'FineTuning': 1, 'Vector Databases': 3, 'Graphical Methods': 1, 'Graph Databases': 1, 'Pattern Mining': 1, 'Decision Trees': 1, 'Probability Networks': 1, 'Association Rules': 1, 'GLMs': 1, 'SVMs': 1, 'HMMs': 1, 'Kanban': 1, 'Version Control': 1, 'Testing': 1, 'Experiment Tracking': 2, 'Distributed Data Processing': 1, 'Agile Development': 2, 'Azure DevOps': 1, 'PyTest': 1, 'unittest': 1, 'MLFlow': 1, 'Pyspark': 1, 'Word2Vec': 1, 'tSNE': 1, 'Prompt Engineering': 1, 'PEFT': 1, 'LoRA': 1, 'RLHF': 1, 'Big Data ETL': 1, 'NiFi': 1, 'StreamSets': 1, 'DoD (Department of Defense)': 1, 'IC (Intelligence Community)': 1, 'Advana': 1, 'Actuarial Data Scientist': 1, 'Pricing and other enterprise models': 1, 'Data exploration': 1, 'Data wrangling': 1, 'Analysis': 1, 'Deployment into production': 1, 'IT': 1, 'Predictive modeling projects': 1, 'Predictive modeling techniques': 1, 'Random forest': 1, 'Text mining': 1, 'Nontechnical stakeholders': 1, \"Bachelor's or master's degree\": 1, 'Applied mathematics': 1, 'Quantitative field': 1, 'Insurance designations': 1, 'ACAS': 1, \"3 years' experience\": 1, 'Insurance pricing role': 1, 'Analytical programming languages': 1, 'Psychology': 1, 'Research Methods': 1, 'AI/Data Science': 1, 'Emotion Recognition': 1, 'Expressive Behavior AI': 1, 'Automotive Environments': 1, 'Ethics': 1, 'Collaborative Culture': 1, 'Diversity': 1, 'Continuous Learning': 1, 'Personal Growth': 1, 'Ownership': 1, 'Responsibility': 1, 'Research Project': 1, 'Student Placement': 1, 'Relevant Work Experience': 1, 'Travel': 3, 'Statistical Inference': 2, 'Data Optimization': 2, 'Probability Models': 1, 'Interpersonal Skills': 2, 'Design of Experiment': 1, 'Test Planning': 2, 'Test Design': 1, 'Test Analysis': 1, 'DoD Test and Evaluation': 1, 'Test and Evaluation Level II': 1, 'Secret Security Clearance': 1, 'Defense Acquisition Workforce Improvement Act (DAWIA)': 2, 'Simulations': 1, 'Analysis Activities': 1, 'Simulation Tools': 1, 'Software': 1, 'Microsoft Office Products': 1, 'Word': 1, 'Outlook': 1, 'SharePoint': 1, 'Access': 1, 'Test and Evaluation': 1, 'Medical Insurance': 1, 'Dental Insurance': 1, 'Vision Insurance': 1, 'Life Insurance': 1, 'Disability Insurance': 1, 'Paid Vacation': 1, 'Sick Leave': 1, '401k Plan': 1, 'Tuition Reimbursement': 1, 'Employee Assistance Program': 1, 'Travel Assistance': 1, 'Notebooks': 1, 'Spotfire': 1, 'Jupyter': 1, 'Genomics': 1, 'Team Work': 1, 'Data processing algorithms': 1, 'Postprocessing': 1, 'Predictive algorithms': 1, 'Value added data products': 1, 'Spatially explicit tools': 1, 'Data aggregation': 1, 'Data analytics': 1, 'Matlab': 1, 'C/C++': 1, 'ArcGIS': 1, 'Google EarthEngine': 1, 'Embedded systems': 1, 'Edge computing': 1, 'Micrometeorology': 1, 'Plant physiology': 1, 'Greenhouse gas monitoring': 1, 'Git (Gitlab Github)': 1, 'Quantitative Field': 1, 'Quantitative Analytics': 1, 'Development': 1, 'Task Prioritization': 1, 'Time Management': 1, 'Data Tools': 1, 'R Shiny': 1, 'Business Value': 1, \"Bachelor's Degree in Data Science\": 1, '57 years of Data Science and Machine Learning experience': 1, 'Proficiency with Data Science concepts and modeling techniques': 1, '23 years of experience in CPG and Retail': 1, 'Bias for action': 1, 'Ability to apply various analytical models to business use cases': 1, 'Exceptional communication and collaboration skills': 1, 'Experience with data visualization tools': 1, 'Hybrid work setup in Nashville': 1}\n"}]},{"source":"# Import process from thefuzz\nfrom thefuzz import process # Levenshtein algorithm\n\n# Store the unique values of cuisine_type in unique_types\nunique_types = cols_count.keys()\n\n# Function to clean DataFrame based on similarity scores\ndef clean_dataframe(df, threshold=80):\n    # Count occurrences of each entry\n    cols_count = df.stack().value_counts().to_dict()\n    \n    # Calculate similarity of 'Data Analytics', 'Data Visualization', 'Tableau', and 'Power BI' to all values\n    skills = ['Data Analysis','Data Analytics', 'Data Visualization', 'Tableau', 'Power BI', 'SQL','.Net','A/B Testing','Business Intelligence','Database Management','Data Science']\n    \n    for skill in skills:\n        matches = process.extract(skill, cols_count.keys())\n        # Iterate through the list of matches\n        for match in matches:\n            # Check whether the similarity score is greater than or equal to threshold\n            if match[1] >= threshold:\n                # Replace the matched entry in DataFrame\n                df.replace(match[0], skill, inplace=True)\n    \n    return df\n\n\n# Applying cleaning function to DataFrame\ntest = clean_dataframe(skills_df)\ntest = test.replace('.*AWS.*', 'AWS', regex=True)\ntest = test.replace('.*Amazon.*', 'AWS', regex=True)\ntest = test.replace('.*Agile.*', 'Agile Method', regex=True)\ntest = test.replace('.*SQL.*', 'SQL', regex=True)\ntest = test.replace('.*API.*', 'API', regex=True)\ntest = test.replace('.*Azure.*', 'Azure', regex=True)\ntest = test.replace('.*Tableau.*', 'Data Visualization', regex=True)\ntest = test.replace('.*Power BI.*', 'Data Visualization', regex=True)\ntest = test.replace('.*Business Intelligence*', 'Data Visualization', regex=True)\ntest = test.replace('.*Data Visualisation*', 'Data Visualization', regex=True)\ntest = test.replace('.*Data Integration*', 'ETL/ELT', regex=True)\ntest = test.replace('.*Computer Science*', 'ETL/ELT', regex=True)\ntest = test.replace('.*Data validation*', 'ETL/ELT', regex=True)\ntest = test.replace('.*Data collection*', 'ETL/ELT', regex=True)\ntest = test.replace('.*Data consistency*', 'ETL/ELT', regex=True)\ntest = test.replace('.*Data integrity*', 'Data Analytics', regex=True)\ntest = test.replace('.*Data Analysis*', 'Data Analytics', regex=True)\ntest = test.replace('.*Data Exploration*', 'Data Analytics', regex=True)\ntest = test.replace('.*Extraction*', 'ETL/ELT', regex=True)\ntest = test.replace('.*Database*', 'Database Management', regex=True)\ntest = test.replace('.*Data Engineering*', 'ETL/ELT', regex=True)\ntest = test.replace('.*Data Wrangling*', 'ETL/ELT', regex=True)\ntest = test.replace('.*Data Pipelines*', 'ETL/ELT', regex=True)\ntest = test.replace('.*Data Security*', 'ETL/ELT', regex=True)\ntest = test.replace('.*Data Modeling*', 'ETL/ELT', regex=True)\ntset = test.replace('.*Data Management*', 'ETL/ELT', regex=True)\ntest = test.replace('.*python*', 'Python', regex=True)\n\ncols_count2 = {}\nfor row in [test.iloc[i,:].tolist() for i in range(0,len(test))]:\n    for entry in row:\n        if entry in cols_count2.keys():\n            cols_count2[entry] += 1\n        else:\n            cols_count2[entry] = 1\n            \n# print(cols_count2)\n\n\ntest2 = pd.DataFrame.from_dict(cols_count2,orient='index')\ntest2 = test2.reset_index()\n# print(test2.info())\ntest2.rename(columns={'index':'skill',0:'counts'},inplace = True)\n\n\ntest2_sorted = test2[test2['skill'] != ''].sort_values(by='counts', ascending=False)\n# Print the sorted DataFrame\nprint(test2_sorted.head(20))\n\n# filter_dict = {}\n# for row, item in enumerate(cols_count2):\n#     for key, value in enumerate(item):\n#         if int(value) > 5:\n#             filter_dict[key] = value\n\n# print(filter_dict)\n# print(sorted((cols_count2.values())))\n\n# value = {i for i in cols_count2 if cols_count2[i]==696}\n# print(\"key by value:\",value)","metadata":{"executionCancelledAt":null,"executionTime":333,"lastExecutedAt":1712957475451,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Import process from thefuzz\nfrom thefuzz import process # Levenshtein algorithm\n\n# Store the unique values of cuisine_type in unique_types\nunique_types = cols_count.keys()\n\n# Function to clean DataFrame based on similarity scores\ndef clean_dataframe(df, threshold=80):\n    # Count occurrences of each entry\n    cols_count = df.stack().value_counts().to_dict()\n    \n    # Calculate similarity of 'Data Analytics', 'Data Visualization', 'Tableau', and 'Power BI' to all values\n    skills = ['Data Analysis','Data Analytics', 'Data Visualization', 'Tableau', 'Power BI', 'SQL','.Net','A/B Testing','Business Intelligence','Database Management']\n    \n    for skill in skills:\n        matches = process.extract(skill, cols_count.keys())\n        # Iterate through the list of matches\n        for match in matches:\n            # Check whether the similarity score is greater than or equal to threshold\n            if match[1] >= threshold:\n                # Replace the matched entry in DataFrame\n                df.replace(match[0], skill, inplace=True)\n    \n    return df\n\n\n# Applying cleaning function to DataFrame\ntest = clean_dataframe(skills_df)\ntest = test.replace('.*AWS.*', 'AWS', regex=True)\ntest = test.replace('.*Amazon.*', 'AWS', regex=True)\ntest = test.replace('.*Agile.*', 'Agile Method', regex=True)\ntest = test.replace('.*SQL.*', 'SQL', regex=True)\ntest = test.replace('.*API.*', 'API', regex=True)\ntest = test.replace('.*Azure.*', 'Azure', regex=True)\ntest = test.replace('.*Tableau.*', 'Data Visualization', regex=True)\ntest = test.replace('.*Power BI.*', 'Data Visualization', regex=True)\ntest = test.replace('.*Business Intelligence*', 'Data Visualization', regex=True)\ntest = test.replace('.*Data Visualisation*', 'Data Visualization', regex=True)\ntest = test.replace('.*Data Integration*', 'ETL/ELT', regex=True)\ntest = test.replace('.*Computer Science*', 'ETL/ELT', regex=True)\ntest = test.replace('.*Data validation*', 'ETL/ELT', regex=True)\ntest = test.replace('.*Data collection*', 'ETL/ELT', regex=True)\ntest = test.replace('.*Data consistency*', 'ETL/ELT', regex=True)\ntest = test.replace('.*Data integrity*', 'Data Analytics', regex=True)\ntest = test.replace('.*Data Analysis*', 'Data Analytics', regex=True)\ntest = test.replace('.*Data Exploration*', 'Data Analytics', regex=True)\ntest = test.replace('.*Extraction*', 'ETL/ELT', regex=True)\ntest = test.replace('.*Database*', 'Database Management', regex=True)\ntest = test.replace('.*Data Engineering*', 'ETL/ELT', regex=True)\ntest = test.replace('.*Data Wrangling*', 'ETL/ELT', regex=True)\ntest = test.replace('.*Data Pipelines*', 'ETL/ELT', regex=True)\ntest = test.replace('.*Data Security*', 'ETL/ELT', regex=True)\ntest = test.replace('.*Data Modeling*', 'ETL/ELT', regex=True)\ntset = test.replace('.*Data Management*', 'ETL/ELT', regex=True)\ntest = test.replace('.*python*', 'Python', regex=True)\n\ncols_count2 = {}\nfor row in [test.iloc[i,:].tolist() for i in range(0,len(test))]:\n    for entry in row:\n        if entry in cols_count2.keys():\n            cols_count2[entry] += 1\n        else:\n            cols_count2[entry] = 1\n            \n# print(cols_count2)\n\n\ntest2 = pd.DataFrame.from_dict(cols_count2,orient='index')\ntest2 = test2.reset_index()\n# print(test2.info())\ntest2.rename(columns={'index':'skill',0:'counts'},inplace = True)\n\n\ntest2_sorted = test2[test2['skill'] != ''].sort_values(by='counts', ascending=False)\n# Print the sorted DataFrame\nprint(test2_sorted.head(20))\n\n# filter_dict = {}\n# for row, item in enumerate(cols_count2):\n#     for key, value in enumerate(item):\n#         if int(value) > 5:\n#             filter_dict[key] = value\n\n# print(filter_dict)\n# print(sorted((cols_count2.values())))\n\n# value = {i for i in cols_count2 if cols_count2[i]==696}\n# print(\"key by value:\",value)","outputsMetadata":{"0":{"height":428,"type":"stream"},"1":{"height":217,"type":"stream"},"2":{"height":417,"type":"stream"},"3":{"height":217,"type":"stream"},"4":{"height":417,"type":"stream"},"5":{"height":217,"type":"stream"},"6":{"height":417,"type":"stream"},"7":{"height":217,"type":"stream"},"8":{"height":417,"type":"stream"},"9":{"height":217,"type":"stream"},"10":{"height":417,"type":"stream"},"11":{"height":217,"type":"stream"},"12":{"height":417,"type":"stream"},"13":{"height":217,"type":"stream"}},"lastExecutedByKernel":"ce4fc287-1b09-4712-9568-685b14a7dd2a"},"id":"4","cell_type":"code","execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":"                  skill  counts\n93   Data Visualization      75\n31               Python      65\n34                  SQL      56\n110      Data Analytics      55\n61         Data Science      45\n65     Machine Learning      45\n90              ETL/ELT      45\n13                    R      38\n5            Statistics      26\n245       Communication      20\n75                Spark      18\n76               Hadoop      18\n0      Machine learning      17\n41                  AWS      17\n205         Data Mining      16\n100        Data science      12\n114          Clustering      12\n42                 Java      12\n1            Regression      11\n115      Classification      10\n"}]}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":5}